###FORMAT:
Title: Police algorithm said Lina was at 'medium' risk. Then she was killed
URL: https://www.bbc.com/news/articles/clyw7g4zxwzo
Scraped Date: 2025-04-20 12:43:49
Published Date: 2025-04-19

--- Text ---
Police algorithm said Lina was at 'medium' risk. Then she was killed
In January, Lina went to the police.
Her ex-partner had been threatening her at home in the Spanish seaside town of Benalmádena. That day, he'd allegedly raised his hand as if to hit her.
"There had been violent episodes - she was scared," Lina's cousin Daniel recalls.
When she got to the police station, she was interviewed and her case registered with VioGén, a digital tool which assesses the likelihood of a woman being attacked again by the same man.
VioGén - an algorithm-based system - asks 35 questions about the abuse and its intensity, the aggressor's access to weapons, his mental health and whether the woman has left, or is considering leaving, the relationship.
It then records the threat to her as "negligible", "low", "medium", "high" or "extreme".
The category is used to make decisions about the allocation of police resources to protect the woman.
Lina was deemed to be at "medium" risk.
She asked for a restraining order at a specialist gender violence court in Malaga, so that her ex-partner couldn't be in contact with her or share her living space. The request was denied.
"Lina wanted to change the locks at her home, so she could live peacefully with her children," says her cousin.
Three weeks later, she was dead. Her partner had allegedly used his key to enter her flat and soon the house was on fire.
While her children, mother and ex-partner all escaped, Lina didn't. Her 11-year-old son was widely reported as telling police it was his father who killed his mother.
Lina's lifeless body was retrieved from the charred interior of her home. Her ex-partner, the father of her three youngest children, was arrested.
Now, her death is raising questions about VioGén and its ability to keep women safe in Spain.
VioGén didn't accurately predict the threat to Lina.
As a woman designated at "medium" risk, the protocol is that she would be followed up again by a nominated police officer within 30 days.
But Lina was dead before that. If she had been "high" risk, the police follow-up would have happened within a week. Could that have made a difference to Lina?
Tools to evaluate the threat of repeat domestic violence are used in North America and across Europe. In the UK, some police forces use DARA (Domestic Abuse Risk Assessment) - essentially a checklist. And DASH (Domestic Abuse, Stalking, Harassment and Honour-based Violence Assessment) may be employed by police or others, like social workers, to assess the risk of another attack.
But only in Spain is an algorithm woven so tightly into police practice. VioGén was developed by Spanish police and academics. It's used everywhere apart from the Basque Country and Catalonia (those regions have separate systems, although police co-operation is nationwide).
The head of the National Police's family and women's unit in Malaga, Ch Insp Isabel Espejo, describes VioGén as "super-important".
"It helps us follow each victim's case very precisely," she says.
Her officers deal with an average of 10 reports of gender violence a day. And every month, VioGén classifies nine or 10 women as being at "extreme" risk of repeat victimisation.
The resource implications in those cases are huge: 24-hour police protection for a woman until the circumstances change and the risk decreases. Women assessed as "high" risk may also get an officer escort.
A 2014 study found that officers accepted VioGén's evaluation of the likelihood of repeated abuse 95% of the time. Critics suggest police are abdicating decision-making about women's safety to an algorithm.
Ch Insp Espejo says that the algorithm's calculation of risk is usually adequate. But she recognises - even though Lina's case wasn't under her command - that something went wrong with Lina's assessment.
"I'm not going to say VioGén doesn't fail – it does. But this wasn't the trigger that led to this woman's murder. The only guilty party is the person who killed Lina. Total security just doesn't exist," she says.
But at "medium" risk, Lina was never a police priority. And did Lina's VioGén assessment have an impact on the court's decision to deny her a restraining order against her ex-partner?
Court authorities didn't give us permission to meet the judge who denied Lina an injunction against her ex-partner - a woman attacked on social media after Lina's death.
Instead, another of Malaga's gender violence judges, Maria del Carmen Gutiérrez tells us in general terms that such an order needs two things: evidence of a crime and the threat of serious danger to the victim.
"VioGén is one element I use to assess that danger, but it's far from the only one," she says.
Sometimes, the judge says, she makes restraining orders in cases where VioGén has assessed a woman as at "negligible" or "low" risk. On other occasions she may conclude there's no danger to a woman deemed at "medium" or "high" risk of repeat victimisation.
Dr Juan Jose Medina, a criminologist at the University of Seville, says Spain has a "postcode lottery" for women applying for restraining orders – some jurisdictions are much more likely to grant them than others. But we don't know systematically how VioGén influences the courts, or the police, because studies haven't been done.
"How are police officers and other stakeholders using this tool, and how is it informing their decision-making? We don't have good answers," he says.
Spain's interior ministry hasn't often allowed academics access to VioGén's data. And there hasn't been an independent audit of the algorithm.
Gemma Galdon, the founder of Eticas – an organisation working on the social and ethical impact of technology – says if you don't audit these systems, you won't know if they're actually delivering police protection to the right women.
Examples of algorithmic bias elsewhere are well-documented. In the US, analysis from 2016 of a recidivism tool found black defendants were more likely than their white peers to be incorrectly judged to be at higher risk of repeat offending. At the same time, white defendants were more likely than black defendants to be wrongly flagged as low risk.
In 2018, Spain's interior ministry didn't give a green light to an Eticas proposal to conduct a confidential, pro-bono, internal audit. So instead, Gemma Galdon and her colleagues decided to reverse-engineer VioGén and do an external audit.
They used interviews with women survivors of domestic abuse and publicly available information - including data from the judiciary about women who, like Lina, had been killed.
They found that between 2003 and 2021, 71 women murdered by their partners or ex-partners had previously reported domestic abuse to the police. Those recorded on the VioGén system were given risk levels of "negligible" or "medium".
"What we'd like to know is, were those error rates that cannot be mitigated in any way? Or could we have done something to improve how these systems assign risk and protect those women better?" asks Gemma Galdon.
The head of gender violence research at Spain's interior ministry, Juan José López-Ossorio, is dismissive of the Eticas investigation: it wasn't done with VioGén data. "If you don't have access to the data, how can you interpret it?" he says.
And he is wary of an external audit, fearing it could compromise both the security of women whose cases are recorded and VioGén's procedures.
"What we know is that once a woman reports a man and she's under police protection, the probability of further violence is substantially lowered - we've no doubts about that," says López-Ossorio.
VioGén has evolved since it was introduced in Spain. The questionnaire has been refined, and the "negligible" category of risk will soon be abolished. And even critics agree it makes sense to have a standardised system responding to gender violence.
In Benalmádena, Lina's home has become a shrine.
Flowers, candles and pictures of saints were left on the step. A small poster stuck on the wall declared: Benalmádena says no to gender violence. The community fundraised for Lina's children.
Her cousin, Daniel, says everyone's still reeling from news of her death.
"The family it's destroyed – especially Lina's mother," he says.
"She's 82 years old. I don't think there's anything sadder than to have your daughter killed by an aggressor in a way that could have been avoided. The children are still in shock – they'll need a lot of psychological help."
