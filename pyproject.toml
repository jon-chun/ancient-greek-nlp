[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "news-scraper"
version = "0.1.0"
description = "A sophisticated utility for crawling news websites with anti-detection measures"
readme = "README.md"
requires-python = ">=3.11"
license = { text = "MIT" }
authors = [
    { name = "Your Name", email = "your.email@example.com" }
]

dependencies = [

    # Core requirements
    "requests==2.32.3",  # Updated to specified version
    "beautifulsoup4==4.13.4",  # Updated to specified version
    "langdetect>=1.0.9",
    "urllib3>=1.26.0",
    "lxml>=4.9.0",  # Often faster for bs4 parsing
    "pyyaml>=6.0",

    # Browser automation
    "playwright>=1.30.0",
    "browser-use>=0.1.0",  # Added browser-use dependency

    # Language models and integrations
    "langchain>=0.3.0",
    "langchain-openai>=0.3.1",
    "langchain-anthropic>=0.3.3",
    "langchain-community>=0.3.0",
    "langchain-core>=0.3.0",
    
    # Google Generative AI
    "google-generativeai",
    
    # Environment variables
    "python-dotenv==1.1.0",  # Updated to specified version

    # Data processing
    "numpy==2.2.5",  # Updated to specified version
    "pandas==2.2.3",  # Added from ###LIBS
    "protobuf<6.0.0,>=3.20.2",  # Modified to be compatible with google-generativeai
    "trafilatura==2.0.0",  # Added from ###LIBS
    
    # Progress tracking
    "tqdm",

    # Optional (but included for convenience)
    "dateparser>=1.1.0",
    # "cchardet>=2.1.0",
    "charset-normalizer>=3.3.0"
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "black>=22.0.0",
    "isort>=5.10.0",
    "flake8>=5.0.0"
]

[project.scripts]
util_get_news_website = "news_scraper.main:main"

[tool.hatch.build.targets.wheel]
packages = ["news_scraper"]

[tool.hatch.build.targets.sdist]
include = ["/news_scraper"]

[tool.pytest.ini_options]
testpaths = ["tests"]

[tool.black]
line-length = 100
target-version = ["py38", "py39", "py310"]

[tool.isort]
profile = "black"
line_length = 100